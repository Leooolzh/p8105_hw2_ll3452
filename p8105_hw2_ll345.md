Assignment 2
================
Leo Liu

``` r
library(tidyverse)
```

    ## ── Attaching packages ─────────────────────────────────────────────────────────── tidyverse 1.3.0 ──

    ## ✓ ggplot2 3.3.2     ✓ purrr   0.3.4
    ## ✓ tibble  3.0.3     ✓ dplyr   1.0.2
    ## ✓ tidyr   1.1.2     ✓ stringr 1.4.0
    ## ✓ readr   1.3.1     ✓ forcats 0.5.0

    ## ── Conflicts ────────────────────────────────────────────────────────────── tidyverse_conflicts() ──
    ## x dplyr::filter() masks stats::filter()
    ## x dplyr::lag()    masks stats::lag()

``` r
library(readxl)
```

## Problem 1

Read the Mr. Trashwheel dataset.

``` r
trashwheel_df = 
   read_xlsx(
     "./Trash-Wheel-Collection-Totals-8-6-19.xlsx",
     range = cell_cols("A:N")) %>% 
  janitor::clean_names() %>% 
  drop_na(dumpster) %>% 
  mutate(
    sports_balls = round(sports_balls)
  )
```

Read Precipitation data

``` r
precip_2018 =
  read_excel("./Trash-Wheel-Collection-Totals-8-6-19.xlsx",
             sheet = "2018 Precipitation",
             skip = 1) %>% 
  janitor::clean_names() %>% 
  drop_na(month) %>% 
  mutate(year = 2018) %>% 
  relocate(year)

precip_2017 =
  read_excel("./Trash-Wheel-Collection-Totals-8-6-19.xlsx",
             sheet = "2017 Precipitation",
             skip = 1) %>% 
  janitor::clean_names() %>% 
  drop_na(month) %>% 
  mutate(year = 2017) %>% 
  relocate(year)
```

Combine the two annual precipitation

``` r
month_df = 
  tibble(
    month = 1:12,
    month_name = month.name
  )

precip_df = 
  bind_rows(precip_2018, precip_2017)

left_join(precip_df, month_df, by = "month")
```

    ## # A tibble: 24 x 4
    ##     year month total month_name
    ##    <dbl> <dbl> <dbl> <chr>     
    ##  1  2018     1  0.94 January   
    ##  2  2018     2  4.8  February  
    ##  3  2018     3  2.69 March     
    ##  4  2018     4  4.69 April     
    ##  5  2018     5  9.27 May       
    ##  6  2018     6  4.77 June      
    ##  7  2018     7 10.2  July      
    ##  8  2018     8  6.45 August    
    ##  9  2018     9 10.5  September 
    ## 10  2018    10  2.12 October   
    ## # … with 14 more rows

The dataset contains information from the Mr. Trashwheel collector in
Baltimore, Maryland. The trashwheel collects the trash when it enters
the inner harbor. The variables included are the dates (year, month,
day) trash is collected, and the types of trash collected. The total
number of entries is 344 in the final dataset. Additional information on
precipitation is included in the rest of the excel sheets. The median
number of sportsballs collected is 8 and the total precipitation in 2018
is 70.33.

Problem 2

First, we want to read the csv file that contains the nyc transit
information. Then, we want to use the r function clean\_names to tidy up
the variable names. We can choose the columns we want to keep using the
r function select, and change the variable entry to logical.

``` r
nyc_transit_df = 
  read_csv("./NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>% 
  janitor:: clean_names() %>% 
  select(line, station_name, station_latitude, station_longitude, starts_with("route"), entry, vending, entrance_type, ada) %>% 
  mutate(
    entry = ifelse(entry == "YES", 1, 0)
  )
```

    ## Parsed with column specification:
    ## cols(
    ##   .default = col_character(),
    ##   `Station Latitude` = col_double(),
    ##   `Station Longitude` = col_double(),
    ##   Route8 = col_double(),
    ##   Route9 = col_double(),
    ##   Route10 = col_double(),
    ##   Route11 = col_double(),
    ##   ADA = col_logical(),
    ##   `Free Crossover` = col_logical(),
    ##   `Entrance Latitude` = col_double(),
    ##   `Entrance Longitude` = col_double()
    ## )

    ## See spec(...) for full column specifications.

``` r
view(nyc_transit_df)
```

The nyc\_transit dataset contains 19 variables, including the lines,
station names, stations’ longitude and latitude, the route names and
numbers, entry types, vending information, whether or not there is
entry, and whether or not the station is ADA compliant. So far, we
cleaned up the names, chose the columns we want to keep, and changed the
variable “entry” to a logical value. 1 means entry is YES, 0 means entry
is NO. The dataset now consists of 1868 rows and 19 columns. However,
more work is needed to be done. The dataset is not yet tidy. the route 1
to 11 should be condensed using pivot\_longer.

``` r
distinct_nyc_transit =
  distinct(nyc_transit_df,
           line,
           station_name,
           .keep_all = TRUE
  )

nrow(distinct_nyc_transit)
```

    ## [1] 465

There are 465 distinct stations 84 are ADA compliant 5 in 9 entries
without vending allow entrance

Since the above dataset is not yet tidy, let’s tidy it up using
pivot\_longer (wide format to long format). I also need to separate
routes with the route number.

``` r
distinct_nyc_longer = 
  distinct_nyc_transit %>% 
  mutate(route8 = as.character(route8),
         route9 = as.character(route9),
         route10 = as.character(route10),
         route11 = as.character(route11)) %>% 
  pivot_longer(
    route1:route11,
    names_to = "routes",
    values_to = "trains") %>% 
  separate(routes, 
           into = c("route_name", "route_number"), 
           sep = 5)
```

We find that 60 distinct stations serve A train, and 924 distinct
stations are ADA compliant.

Problem 3

The following steps will clean the data names, break up the variable mon
into integer variables (year, month, day), replace number with the month
name, create a new variable “president” that take values from the
“prez\_dem” and “prez\_gop” variables, and remove the variable “day”.

``` r
pols_df = 
  read_csv("./fivethirtyeight_datasets/pols-month.csv") %>% 
  janitor::clean_names() %>% 
  separate(mon, into = c("year", "month", "day"), sep = "-") %>% 
  mutate(
    month = month.name[as.numeric(month)],
    president = ifelse(prez_gop == 1, "republican", "democrat")) %>% 
    select(-prez_gop, -prez_dem
  )
```

    ## Parsed with column specification:
    ## cols(
    ##   mon = col_date(format = ""),
    ##   prez_gop = col_double(),
    ##   gov_gop = col_double(),
    ##   sen_gop = col_double(),
    ##   rep_gop = col_double(),
    ##   prez_dem = col_double(),
    ##   gov_dem = col_double(),
    ##   sen_dem = col_double(),
    ##   rep_dem = col_double()
    ## )

Now read the snp.csv file that contains the closing information. Again,
we clean the data names, arrange the columns so that year and month are
the leading columns.

``` r
snp_df = 
  read_csv("./fivethirtyeight_datasets/snp.csv") %>% 
  janitor:: clean_names() %>% 
  separate(date,
           into = c("day", "month", "year"), sep = "/") %>% 
  arrange(year, month, day) %>% 
  mutate(
    month = month.name[as.numeric(month)]) %>% 
  select(year, month, day, close)
```

    ## Parsed with column specification:
    ## cols(
    ##   date = col_character(),
    ##   close = col_double()
    ## )

Next, we read the unemployment.csv and clean names, reformat the dataset
into long format.

``` r
unemp_df = 
  read_csv("./fivethirtyeight_datasets/unemployment.csv") %>% 
  janitor:: clean_names() %>% 
  pivot_longer(jan:dec,
               names_to = "month",
               values_to = "unemployment_rate") %>% 
  mutate(month = recode(month, `jan` = "January",
                        `feb` = "February",
                        `mar` = "March",
                        `apr` = "April",
                        `may` = "May",
                        `jun` = "June",
                        `jul` = "July",
                        `aug` = "August",
                        `sep` = "September",
                        `oct` = "October",
                        `nov` = "November",
                        `dec` = "December"),
         year = as.character(year))
```

    ## Parsed with column specification:
    ## cols(
    ##   Year = col_double(),
    ##   Jan = col_double(),
    ##   Feb = col_double(),
    ##   Mar = col_double(),
    ##   Apr = col_double(),
    ##   May = col_double(),
    ##   Jun = col_double(),
    ##   Jul = col_double(),
    ##   Aug = col_double(),
    ##   Sep = col_double(),
    ##   Oct = col_double(),
    ##   Nov = col_double(),
    ##   Dec = col_double()
    ## )

Join them Note that the days in the pols\_df are all 15, but no 15
exists in the snp\_df. So the “close” column in snp\_df does not show up
in the joint data frame.

``` r
snp_and_pols_df = 
  left_join(pols_df, snp_df)
```

    ## Joining, by = c("year", "month", "day")

``` r
final_df =
  left_join(snp_and_pols_df, unemp_df)
```

    ## Joining, by = c("year", "month")

The pols.csv dataset contains observations of the number of national
politicians who are democratic or republican at any given time. It
includes the date of count, indicators of whether the president is
democratic or republican, number of republican governors and senators on
the given date, number of democratic governors and senators on the given
date, number of democratic representatives on the given date, and the
number of republican representatives on the given date. In the dataset
after tidying, we used the variable “president” to replace the
indicators. The final pols\_df dataset has 822 entries and 10 columns.

The snp.csv dataset contains information on Standard\&Poor’s stock
market index. This dataset has date and close as variables. close is the
closing values of the index on the given date. It has 787 number of
entries and 2 columns.

the unemp\_df contains information on the unemployment rate in the given
month and year. This dataset has 816 number of entries and 3 number of
variables (columns).

In the end, we left-joined the datasets snp and pols.This is supposed to
provide information of the stock market ton top of the political
information gathered. However, no additional information is added
because all stock closing values are recorded on the 15th, and no
information on the 15th is given in the pols dataset. Lastly,
left-joining the previous dataset with unemployment rate provides
information on unemployment on top of the observations of the political
environment.
